{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5d9318",
   "metadata": {},
   "source": [
    "# Streamlit Dashboard for Humor Detection EDA\n",
    "\n",
    "## Overview\n",
    "This notebook creates an interactive Streamlit dashboard for exploring the humor detection dataset. It connects with the main analysis notebook to leverage all the processed data and visualizations.\n",
    "\n",
    "## Dashboard Features\n",
    "1. **Dataset Overview**: Basic statistics and data quality metrics\n",
    "2. **Demographic Analysis**: Interactive exploration of participant demographics\n",
    "3. **Joke Performance Analysis**: Individual joke performance and response patterns\n",
    "4. **Cultural Insights**: Cross-cultural humor patterns and comprehension analysis\n",
    "5. **Advanced Visualizations**: Heatmaps and correlation analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf45949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STREAMLIT DASHBOARD CREATION\n",
    "# This cell creates the complete Streamlit dashboard file\n",
    "\n",
    "dashboard_code = '''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Humor Detection EDA Dashboard\",\n",
    "    page_icon=\":bar_chart:\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Custom CSS for better styling\n",
    "st.markdown(\"\"\"\n",
    "<style>\n",
    ".main-header {\n",
    "    font-size: 2.5rem;\n",
    "    color: #1f77b4;\n",
    "    text-align: center;\n",
    "    margin-bottom: 2rem;\n",
    "}\n",
    ".metric-card {\n",
    "    background-color: #f0f2f6;\n",
    "    padding: 1rem;\n",
    "    border-radius: 0.5rem;\n",
    "    margin: 0.5rem 0;\n",
    "}\n",
    ".insight-box {\n",
    "    padding: 1rem;\n",
    "    border-left: 4px solid #1f77b4;\n",
    "    margin: 1rem 0;\n",
    "}\n",
    "</style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    \"\"\"Load and process the humor detection dataset\"\"\"\n",
    "    try:\n",
    "        # Load the main dataset\n",
    "        df = pd.read_csv('Dataset.csv')\n",
    "        \n",
    "        # Data processing functions (copied from main notebook)\n",
    "        def clean_joke_text(joke_text):\n",
    "            import re\n",
    "            pattern = r'^s\\\\d+:\\\\s*'\n",
    "            cleaned_text = re.sub(pattern, '', joke_text, flags=re.IGNORECASE)\n",
    "            return cleaned_text.strip()\n",
    "        \n",
    "        def standardize_country(country):\n",
    "            if pd.isna(country) or country in ['Unknown', '']:\n",
    "                return 'Unknown'\n",
    "            \n",
    "            country_str = str(country).strip().lower()\n",
    "            \n",
    "            if any(term in country_str for term in ['uk', 'united kingdom', 'england', 'britain', 'british']):\n",
    "                return 'UK'\n",
    "            \n",
    "            country_mapping = {\n",
    "                'usa': 'United States', 'us': 'United States', 'america': 'United States',\n",
    "                'australia': 'Australia', 'canada': 'Canada', 'india': 'India'\n",
    "            }\n",
    "            \n",
    "            return country_mapping.get(country_str, country.strip())\n",
    "        \n",
    "        def standardize_ethnicity(ethnicity):\n",
    "            if pd.isna(ethnicity) or ethnicity in ['Unknown', '']:\n",
    "                return 'Prefer not to say'\n",
    "            \n",
    "            ethnicity_str = str(ethnicity).strip().lower()\n",
    "            \n",
    "            if any(term in ethnicity_str for term in ['indian', 'pakistani', 'bangladeshi', 'south asian']):\n",
    "                return 'South Asian'\n",
    "            elif any(term in ethnicity_str for term in ['white', 'caucasian', 'european', 'british']):\n",
    "                return 'White/Caucasian'\n",
    "            elif any(term in ethnicity_str for term in ['black', 'african', 'caribbean']):\n",
    "                return 'Black/African/Caribbean'\n",
    "            elif any(term in ethnicity_str for term in ['hispanic', 'latino', 'mexican']):\n",
    "                return 'Hispanic/Latino'\n",
    "            elif any(term in ethnicity_str for term in ['chinese', 'japanese', 'korean', 'east asian']):\n",
    "                return 'East Asian'\n",
    "            elif any(term in ethnicity_str for term in ['arab', 'persian', 'middle eastern']):\n",
    "                return 'Middle Eastern/North African'\n",
    "            else:\n",
    "                return 'Other'\n",
    "        \n",
    "        # Process the data\n",
    "        clean_df = df.copy()\n",
    "        \n",
    "        # Find demographic columns\n",
    "        age_col = next((col for col in df.columns if 'Your Age' in col), None)\n",
    "        gender_col = next((col for col in df.columns if 'gender' in col.lower()), None)\n",
    "        ethnicity_col = next((col for col in df.columns if 'ethnic' in col.lower()), None)\n",
    "        \n",
    "        # Find humor columns\n",
    "        humor_cols = [col for col in df.columns if col.startswith('s') and ':' in col]\n",
    "        \n",
    "        # Create processed dataset\n",
    "        final_data = []\n",
    "        for idx, row in clean_df.iterrows():\n",
    "            participant_id = idx\n",
    "            age = row[age_col] if age_col else 'Unknown'\n",
    "            gender = row[gender_col] if gender_col else 'Unknown'\n",
    "            \n",
    "            ethnicity_raw = row[ethnicity_col] if ethnicity_col else 'Unknown'\n",
    "            ethnicity = standardize_ethnicity(ethnicity_raw)\n",
    "            \n",
    "            country_residence = standardize_country(row.get('Country of Residence:', 'Unknown'))\n",
    "            country_birth = standardize_country(row.get('Country of Birth:', 'Unknown'))\n",
    "            \n",
    "            for i, col in enumerate(humor_cols, 1):\n",
    "                response = row[col]\n",
    "                understand_responses = [\"I didn't understand\", \"I didn't understand the statement\"]\n",
    "                if pd.notna(response) and response in ['Yes', 'No'] + understand_responses:\n",
    "                    clean_response = \"I didn't understand\" if response in understand_responses else response\n",
    "                    \n",
    "                    final_data.append({\n",
    "                        'participant_id': participant_id,\n",
    "                        'age': age,\n",
    "                        'gender': gender,\n",
    "                        'ethnicity': ethnicity,\n",
    "                        'country_residence': country_residence,\n",
    "                        'country_birth': country_birth,\n",
    "                        'joke_id': f's{i}',\n",
    "                        'joke_text': clean_joke_text(col),\n",
    "                        'response': clean_response\n",
    "                    })\n",
    "        \n",
    "        final_df = pd.DataFrame(final_data)\n",
    "        return df, final_df, humor_cols\n",
    "        \n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading data: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "def main():\n",
    "    # Main header\n",
    "    st.markdown('<h1 class=\"main-header\">Humor Detection EDA Dashboard</h1>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Load data\n",
    "    with st.spinner('Loading data...'):\n",
    "        raw_df, processed_df, humor_cols = load_data()\n",
    "    \n",
    "    if processed_df is None:\n",
    "        st.error(\"Failed to load data. Please ensure Dataset.csv is in the same directory.\")\n",
    "        return\n",
    "    \n",
    "    # Sidebar navigation\n",
    "    st.sidebar.title(\"Navigation\")\n",
    "    page = st.sidebar.radio(\n",
    "        \"Choose a section:\",\n",
    "        [\"Dataset Overview\", \"Demographics\", \"Joke Performance\", \n",
    "         \"Cultural Analysis\", \"Advanced Insights\"]\n",
    "    )\n",
    "    \n",
    "    # Dataset Overview Page\n",
    "    if page == \"Dataset Overview\":\n",
    "        st.header(\"Dataset Overview\")\n",
    "        \n",
    "        # Key metrics\n",
    "        col1, col2, col3, col4 = st.columns(4)\n",
    "        \n",
    "        with col1:\n",
    "            st.metric(\"Total Participants\", processed_df['participant_id'].nunique())\n",
    "        with col2:\n",
    "            st.metric(\"Total Jokes\", processed_df['joke_id'].nunique())\n",
    "        with col3:\n",
    "            st.metric(\"Total Responses\", len(processed_df))\n",
    "        with col4:\n",
    "            st.metric(\"Response Rate\", f\"{(len(processed_df) / (processed_df['participant_id'].nunique() * processed_df['joke_id'].nunique()) * 100):.1f}%\")\n",
    "        \n",
    "        # Response distribution\n",
    "        st.subheader(\"Response Distribution\")\n",
    "        response_counts = processed_df['response'].value_counts()\n",
    "        \n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            fig_pie = px.pie(values=response_counts.values, names=response_counts.index,\n",
    "                           title=\"Overall Response Distribution\")\n",
    "            st.plotly_chart(fig_pie, use_container_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            fig_bar = px.bar(x=response_counts.index, y=response_counts.values,\n",
    "                           title=\"Response Counts\", labels={'x': 'Response', 'y': 'Count'})\n",
    "            st.plotly_chart(fig_bar, use_container_width=True)\n",
    "        \n",
    "        # Data quality insights\n",
    "        st.markdown('<div class=\"insight-box\"><h4>Key Findings from Response Analysis</h4>', unsafe_allow_html=True)\n",
    "        funny_rate = response_counts['Yes'] / len(processed_df) * 100\n",
    "        not_funny_rate = response_counts['No'] / len(processed_df) * 100\n",
    "        understand_key = \"I didn't understand\"\n",
    "        comprehension_rate = response_counts.get(understand_key, 0) / len(processed_df) * 100\n",
    "        \n",
    "        st.write(f\"• **Humor Appreciation**: {funny_rate:.1f}% of responses found jokes funny, indicating moderate engagement with humor content\")\n",
    "        st.write(f\"• **Clear Rejection**: {not_funny_rate:.1f}% explicitly did not find jokes funny, suggesting diverse humor preferences\")\n",
    "        st.write(f\"• **Comprehension Barriers**: {comprehension_rate:.1f}% had comprehension issues, highlighting potential cultural or linguistic barriers\")\n",
    "        \n",
    "        if funny_rate > 50:\n",
    "            st.write(\"• **Overall Assessment**: Majority positive response suggests effective humor selection for this demographic\")\n",
    "        elif funny_rate > 30:\n",
    "            st.write(\"• **Overall Assessment**: Mixed responses indicate diverse humor preferences across participants\")\n",
    "        else:\n",
    "            st.write(\"• **Overall Assessment**: Lower appreciation rates may indicate cultural specificity or comprehension challenges\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Demographics Page\n",
    "    elif page == \"Demographics\":\n",
    "        st.header(\"Demographic Analysis\")\n",
    "        \n",
    "        # Get unique participants\n",
    "        participants = processed_df.drop_duplicates('participant_id')\n",
    "        \n",
    "        # Age distribution - filter out non-numeric ages\n",
    "        participants_with_age = participants[participants['age'] != 'Unknown'].copy()\n",
    "        participants_with_age['age_numeric'] = pd.to_numeric(participants_with_age['age'], errors='coerce')\n",
    "        participants_with_age = participants_with_age.dropna(subset=['age_numeric'])\n",
    "        \n",
    "        if len(participants_with_age) > 0:\n",
    "            st.subheader(\"Age Distribution\")\n",
    "            fig_age = px.histogram(participants_with_age, x='age_numeric', nbins=15, \n",
    "                                 title=\"Age Distribution of Participants\",\n",
    "                                 labels={'age_numeric': 'Age', 'count': 'Number of Participants'})\n",
    "            st.plotly_chart(fig_age, use_container_width=True)\n",
    "        else:\n",
    "            st.subheader(\"Age Distribution\")\n",
    "            st.write(\"No valid age data available for visualization.\")\n",
    "        \n",
    "        # Ethnicity and Gender\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"Ethnicity Distribution\")\n",
    "            ethnicity_counts = participants['ethnicity'].value_counts()\n",
    "            fig_eth = px.bar(x=ethnicity_counts.values, y=ethnicity_counts.index, orientation='h',\n",
    "                           title=\"Participants by Ethnicity\")\n",
    "            fig_eth.update_layout(height=400)\n",
    "            st.plotly_chart(fig_eth, use_container_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"Gender Distribution\")\n",
    "            gender_counts = participants['gender'].value_counts()\n",
    "            fig_gender = px.pie(values=gender_counts.values, names=gender_counts.index,\n",
    "                              title=\"Gender Distribution\")\n",
    "            st.plotly_chart(fig_gender, use_container_width=True)\n",
    "        \n",
    "        # Geographic analysis\n",
    "        st.subheader(\"Geographic Distribution\")\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            residence_counts = participants['country_residence'].value_counts().head(10)\n",
    "            fig_res = px.bar(x=residence_counts.values, y=residence_counts.index, orientation='h',\n",
    "                           title=\"Top 10 Countries of Residence\")\n",
    "            st.plotly_chart(fig_res, use_container_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            birth_counts = participants['country_birth'].value_counts().head(10)\n",
    "            fig_birth = px.bar(x=birth_counts.values, y=birth_counts.index, orientation='h',\n",
    "                             title=\"Top 10 Countries of Birth\")\n",
    "            st.plotly_chart(fig_birth, use_container_width=True)\n",
    "        \n",
    "        # Demographic insights\n",
    "        st.markdown('<div class=\"insight-box\"><h4>Demographic Profile Insights</h4>', unsafe_allow_html=True)\n",
    "        total_participants = len(participants)\n",
    "        age_range = f\"{participants_with_age['age_numeric'].min():.0f}-{participants_with_age['age_numeric'].max():.0f}\" if len(participants_with_age) > 0 else \"Unknown\"\n",
    "        dominant_ethnicity = participants['ethnicity'].value_counts().index[0]\n",
    "        dominant_gender = participants['gender'].value_counts().index[0]\n",
    "        \n",
    "        st.write(f\"• **Sample Size**: {total_participants} participants provide robust data for humor analysis\")\n",
    "        st.write(f\"• **Age Demographics**: Age range of {age_range} years suggests focus on young adult perspectives\")\n",
    "        st.write(f\"• **Cultural Diversity**: {participants['ethnicity'].nunique()} ethnic groups represented, with {dominant_ethnicity} being most prevalent\")\n",
    "        st.write(f\"• **Gender Balance**: {dominant_gender} participants comprise {participants['gender'].value_counts().iloc[0]/total_participants*100:.1f}% of sample\")\n",
    "        \n",
    "        # Geographic mobility analysis\n",
    "        migrants = (participants['country_birth'] != participants['country_residence']).sum()\n",
    "        mobility_rate = migrants / total_participants * 100\n",
    "        st.write(f\"• **Geographic Mobility**: {mobility_rate:.1f}% of participants are migrants, offering cross-cultural humor perspectives\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Joke Performance Page\n",
    "    elif page == \"Joke Performance\":\n",
    "        st.header(\"Joke Performance Analysis\")\n",
    "        \n",
    "        # Individual joke performance\n",
    "        joke_stats = processed_df.groupby('joke_id')['response'].value_counts().unstack(fill_value=0)\n",
    "        joke_stats['total'] = joke_stats.sum(axis=1)\n",
    "        joke_stats['funny_rate'] = (joke_stats['Yes'] / joke_stats['total'] * 100).round(1)\n",
    "        \n",
    "        # Handle the \"I didn't understand\" response separately to avoid f-string backslash issue\n",
    "        understand_key = \"I didn't understand\"\n",
    "        joke_stats['comprehension_issues'] = (joke_stats.get(understand_key, 0) / joke_stats['total'] * 100).round(1)\n",
    "        \n",
    "        # Top and bottom performers\n",
    "        col1, col2 = st.columns(2)\n",
    "        \n",
    "        with col1:\n",
    "            st.subheader(\"Top 10 Funniest Jokes\")\n",
    "            top_jokes = joke_stats.nlargest(10, 'funny_rate')[['funny_rate', 'total']]\n",
    "            fig_top = px.bar(x=top_jokes.index, y=top_jokes['funny_rate'],\n",
    "                           title=\"Highest Rated Jokes (%)\", labels={'y': 'Funny Rate (%)', 'x': 'Joke ID'})\n",
    "            st.plotly_chart(fig_top, use_container_width=True)\n",
    "        \n",
    "        with col2:\n",
    "            st.subheader(\"Comprehension Challenges\")\n",
    "            comp_issues = joke_stats.nlargest(10, 'comprehension_issues')[['comprehension_issues', 'total']]\n",
    "            fig_comp = px.bar(x=comp_issues.index, y=comp_issues['comprehension_issues'],\n",
    "                            title=\"Jokes with Comprehension Issues (%)\", \n",
    "                            labels={'y': 'Comprehension Issues (%)', 'x': 'Joke ID'})\n",
    "            st.plotly_chart(fig_comp, use_container_width=True)\n",
    "        \n",
    "        # Interactive joke selector\n",
    "        st.subheader(\"Detailed Joke Analysis\")\n",
    "        selected_joke = st.selectbox(\"Select a joke to analyze:\", joke_stats.index.tolist())\n",
    "        \n",
    "        if selected_joke:\n",
    "            joke_data = processed_df[processed_df['joke_id'] == selected_joke]\n",
    "            joke_text = joke_data['joke_text'].iloc[0]\n",
    "            \n",
    "            st.markdown(f\"**Joke Text:** {joke_text}\")\n",
    "            \n",
    "            col1, col2, col3 = st.columns(3)\n",
    "            with col1:\n",
    "                st.metric(\"Funny Rate\", f\"{joke_stats.loc[selected_joke, 'funny_rate']:.1f}%\")\n",
    "            with col2:\n",
    "                st.metric(\"Total Responses\", joke_stats.loc[selected_joke, 'total'])\n",
    "            with col3:\n",
    "                st.metric(\"Comprehension Issues\", f\"{joke_stats.loc[selected_joke, 'comprehension_issues']:.1f}%\")\n",
    "            \n",
    "            # Response breakdown by demographics\n",
    "            st.subheader(f\"Response Breakdown for {selected_joke}\")\n",
    "            \n",
    "            col1, col2 = st.columns(2)\n",
    "            \n",
    "            with col1:\n",
    "                eth_responses = joke_data.groupby(['ethnicity', 'response']).size().unstack(fill_value=0)\n",
    "                if not eth_responses.empty:\n",
    "                    fig_eth_resp = px.bar(eth_responses, title=f\"Responses by Ethnicity - {selected_joke}\")\n",
    "                    st.plotly_chart(fig_eth_resp, use_container_width=True)\n",
    "            \n",
    "            with col2:\n",
    "                gender_responses = joke_data.groupby(['gender', 'response']).size().unstack(fill_value=0)\n",
    "                if not gender_responses.empty:\n",
    "                    fig_gender_resp = px.bar(gender_responses, title=f\"Responses by Gender - {selected_joke}\")\n",
    "                    st.plotly_chart(fig_gender_resp, use_container_width=True)\n",
    "        \n",
    "        # Performance insights\n",
    "        st.markdown('<div class=\"insight-box\"><h4>Joke Performance Analysis Insights</h4>', unsafe_allow_html=True)\n",
    "        top_performer = joke_stats.loc[joke_stats['funny_rate'].idxmax()]\n",
    "        worst_performer = joke_stats.loc[joke_stats['funny_rate'].idxmin()]\n",
    "        avg_funny_rate = joke_stats['funny_rate'].mean()\n",
    "        most_confusing = joke_stats.loc[joke_stats['comprehension_issues'].idxmax()]\n",
    "        \n",
    "        st.write(f\"• **Top Performer**: {top_performer.name} achieved {top_performer['funny_rate']:.1f}% funny rating, demonstrating broad appeal\")\n",
    "        st.write(f\"• **Performance Range**: Funny rates vary from {worst_performer['funny_rate']:.1f}% to {top_performer['funny_rate']:.1f}%, indicating diverse joke effectiveness\")\n",
    "        st.write(f\"• **Average Appeal**: Mean funny rate of {avg_funny_rate:.1f}% suggests moderate overall humor success\")\n",
    "        st.write(f\"• **Comprehension Challenge**: {most_confusing.name} had {most_confusing['comprehension_issues']:.1f}% comprehension issues, possibly due to cultural references or complexity\")\n",
    "        \n",
    "        high_performers = (joke_stats['funny_rate'] > avg_funny_rate + 10).sum()\n",
    "        st.write(f\"• **Standout Content**: {high_performers} jokes significantly exceeded average performance, indicating successful humor elements\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Cultural Analysis Page\n",
    "    elif page == \"Cultural Analysis\":\n",
    "        st.header(\"Cross-Cultural Humor Analysis\")\n",
    "        \n",
    "        # Age group analysis\n",
    "        participants = processed_df.drop_duplicates('participant_id')\n",
    "        \n",
    "        # Filter out non-numeric ages and convert to numeric\n",
    "        participants_numeric_age = participants[participants['age'] != 'Unknown'].copy()\n",
    "        participants_numeric_age['age'] = pd.to_numeric(participants_numeric_age['age'], errors='coerce')\n",
    "        participants_numeric_age = participants_numeric_age.dropna(subset=['age'])\n",
    "        \n",
    "        if len(participants_numeric_age) > 0:\n",
    "            participants_numeric_age['age_group'] = pd.cut(participants_numeric_age['age'], \n",
    "                                             bins=[0, 25, 35, 45, 100], \n",
    "                                             labels=['18-25', '26-35', '36-45', '46+'])\n",
    "            \n",
    "            # Merge age groups back\n",
    "            df_with_age_groups = processed_df.merge(\n",
    "                participants_numeric_age[['participant_id', 'age_group']], on='participant_id', how='left'\n",
    "            )\n",
    "        else:\n",
    "            # If no valid ages, create empty age_group column\n",
    "            df_with_age_groups = processed_df.copy()\n",
    "            df_with_age_groups['age_group'] = None\n",
    "        \n",
    "        # Cultural patterns\n",
    "        st.subheader(\"Humor Preferences by Demographics\")\n",
    "        \n",
    "        demo_choice = st.selectbox(\n",
    "            \"Select demographic dimension:\",\n",
    "            [\"Age Group\", \"Ethnicity\", \"Gender\", \"Geographic Mobility\"]\n",
    "        )\n",
    "        \n",
    "        if demo_choice == \"Age Group\":\n",
    "            demo_col = 'age_group'\n",
    "            df_demo = df_with_age_groups\n",
    "        elif demo_choice == \"Geographic Mobility\":\n",
    "            # Add mobility indicator\n",
    "            df_demo = processed_df.copy()\n",
    "            df_demo['mobility'] = df_demo['country_birth'] != df_demo['country_residence']\n",
    "            df_demo['mobility'] = df_demo['mobility'].map({True: 'Migrant', False: 'Resident'})\n",
    "            demo_col = 'mobility'\n",
    "        elif demo_choice == \"Ethnicity\":\n",
    "            demo_col = 'ethnicity'\n",
    "            df_demo = processed_df\n",
    "        elif demo_choice == \"Gender\":\n",
    "            demo_col = 'gender'\n",
    "            df_demo = processed_df\n",
    "        else:\n",
    "            demo_col = demo_choice.lower()\n",
    "            df_demo = processed_df\n",
    "        \n",
    "        # Calculate percentages\n",
    "        demo_analysis = df_demo.groupby([demo_col, 'response']).size().unstack(fill_value=0)\n",
    "        demo_percentages = demo_analysis.div(demo_analysis.sum(axis=1), axis=0) * 100\n",
    "        \n",
    "        # Visualization\n",
    "        fig_demo = px.bar(demo_percentages, title=f\"Humor Preferences by {demo_choice} (%)\")\n",
    "        fig_demo.update_layout(height=500)\n",
    "        st.plotly_chart(fig_demo, use_container_width=True)\n",
    "        \n",
    "        # Insights\n",
    "        if 'Yes' in demo_percentages.columns:\n",
    "            most_appreciative = demo_percentages['Yes'].idxmax()\n",
    "            least_appreciative = demo_percentages['Yes'].idxmin()\n",
    "            variance = demo_percentages['Yes'].std()\n",
    "            \n",
    "            st.markdown('<div class=\"insight-box\">', unsafe_allow_html=True)\n",
    "            st.write(f\"**Cross-Cultural Humor Analysis - {demo_choice}:**\")\n",
    "            st.write(f\"• **Highest Appreciation**: {most_appreciative} group shows {demo_percentages.loc[most_appreciative, 'Yes']:.1f}% humor appreciation\")\n",
    "            st.write(f\"• **Lowest Appreciation**: {least_appreciative} group shows {demo_percentages.loc[least_appreciative, 'Yes']:.1f}% humor appreciation\")\n",
    "            st.write(f\"• **Cultural Variance**: {variance:.1f}% standard deviation indicates {'high' if variance > 15 else 'moderate' if variance > 8 else 'low'} cultural specificity in humor preferences\")\n",
    "            \n",
    "            if demo_choice == \"Age Group\":\n",
    "                st.write(\"• **Age Factor**: Generational differences in humor appreciation may reflect varying cultural exposures and communication styles\")\n",
    "            elif demo_choice == \"Ethnicity\":\n",
    "                st.write(\"• **Cultural Impact**: Ethnic variation in humor appreciation highlights the role of cultural background in comedy comprehension\")\n",
    "            elif demo_choice == \"Geographic Mobility\":\n",
    "                st.write(\"• **Migration Effect**: Differences between migrants and residents suggest cultural adaptation influences humor perception\")\n",
    "            st.markdown('</div>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Comprehension analysis\n",
    "        st.subheader(\"Comprehension Challenges by Culture\")\n",
    "        \n",
    "        understand_key = \"I didn't understand\"\n",
    "        if understand_key in df_demo['response'].values:\n",
    "            comp_by_ethnicity = df_demo[df_demo['response'] == understand_key].groupby('ethnicity').size()\n",
    "            total_by_ethnicity = df_demo.groupby('ethnicity').size()\n",
    "            comp_rates = (comp_by_ethnicity / total_by_ethnicity * 100).fillna(0).sort_values(ascending=False)\n",
    "            \n",
    "            fig_comp_cult = px.bar(x=comp_rates.values, y=comp_rates.index, orientation='h',\n",
    "                                 title=\"Comprehension Difficulty by Ethnicity (%)\",\n",
    "                                 labels={'x': 'Comprehension Issues (%)', 'y': 'Ethnicity'})\n",
    "            st.plotly_chart(fig_comp_cult, use_container_width=True)\n",
    "            \n",
    "            # Comprehension insights\n",
    "            st.markdown('<div class=\"insight-box\"><h4>Cultural Comprehension Analysis</h4>', unsafe_allow_html=True)\n",
    "            highest_difficulty = comp_rates.index[0] if len(comp_rates) > 0 else \"None\"\n",
    "            lowest_difficulty = comp_rates.index[-1] if len(comp_rates) > 0 else \"None\"\n",
    "            \n",
    "            st.write(f\"• **Comprehension Barriers**: {highest_difficulty} group shows highest comprehension difficulty, suggesting cultural or linguistic challenges\")\n",
    "            st.write(f\"• **Cultural Accessibility**: {lowest_difficulty} group demonstrates better humor comprehension, indicating cultural alignment with content\")\n",
    "            st.write(f\"• **Language Factor**: Comprehension issues may reflect varying English proficiency or cultural reference familiarity\")\n",
    "            st.write(f\"• **Design Implication**: Future humor content should consider cultural context and linguistic accessibility for diverse audiences\")\n",
    "            st.markdown('</div>', unsafe_allow_html=True)\n",
    "    \n",
    "    # Advanced Insights Page\n",
    "    elif page == \"Advanced Insights\":\n",
    "        st.header(\"Advanced Analytics & Insights\")\n",
    "        \n",
    "        # Cultural specificity analysis\n",
    "        st.subheader(\"Cultural Specificity Analysis\")\n",
    "        \n",
    "        # Calculate cultural variance for each joke\n",
    "        cultural_variance = []\n",
    "        for joke_id in processed_df['joke_id'].unique():\n",
    "            joke_data = processed_df[processed_df['joke_id'] == joke_id]\n",
    "            \n",
    "            # Performance by ethnicity\n",
    "            eth_performance = []\n",
    "            for ethnicity in joke_data['ethnicity'].unique():\n",
    "                eth_subset = joke_data[joke_data['ethnicity'] == ethnicity]\n",
    "                if len(eth_subset) >= 3:  # Minimum sample size\n",
    "                    yes_rate = (eth_subset['response'] == 'Yes').mean() * 100\n",
    "                    eth_performance.append(yes_rate)\n",
    "            \n",
    "            variance = np.std(eth_performance) if len(eth_performance) > 1 else 0\n",
    "            overall_performance = (joke_data['response'] == 'Yes').mean() * 100\n",
    "            \n",
    "            cultural_variance.append({\n",
    "                'joke_id': joke_id,\n",
    "                'cultural_variance': variance,\n",
    "                'overall_performance': overall_performance\n",
    "            })\n",
    "        \n",
    "        cultural_df = pd.DataFrame(cultural_variance)\n",
    "        \n",
    "        # Scatter plot\n",
    "        fig_cultural = px.scatter(cultural_df, \n",
    "                                x='cultural_variance', \n",
    "                                y='overall_performance',\n",
    "                                hover_data=['joke_id'],\n",
    "                                title=\"Cultural Specificity vs Overall Performance\",\n",
    "                                labels={'cultural_variance': 'Cultural Variance', \n",
    "                                       'overall_performance': 'Overall Performance (%)'})\n",
    "        st.plotly_chart(fig_cultural, use_container_width=True)\n",
    "        \n",
    "        # Key insights\n",
    "        correlation = cultural_df['cultural_variance'].corr(cultural_df['overall_performance'])\n",
    "        high_universal = cultural_df[(cultural_df['cultural_variance'] < cultural_df['cultural_variance'].median()) & \n",
    "                                   (cultural_df['overall_performance'] > cultural_df['overall_performance'].median())]\n",
    "        high_specific = cultural_df[cultural_df['cultural_variance'] > cultural_df['cultural_variance'].quantile(0.75)]\n",
    "        \n",
    "        st.markdown('<div class=\"insight-box\">', unsafe_allow_html=True)\n",
    "        st.write(\"**Advanced Statistical Insights:**\")\n",
    "        st.write(f\"• **Universality vs Performance**: Correlation of {correlation:.3f} suggests {'strong' if abs(correlation) > 0.5 else 'moderate' if abs(correlation) > 0.3 else 'weak'} relationship between cultural specificity and performance\")\n",
    "        st.write(f\"• **Universal Appeals**: {len(high_universal)} jokes demonstrate broad cross-cultural appeal with high performance and low variance\")\n",
    "        st.write(f\"• **Cultural Specificity**: {len(high_specific)} jokes show high cultural variance, indicating audience-specific humor preferences\")\n",
    "        \n",
    "        if correlation < -0.3:\n",
    "            st.write(\"• **Key Finding**: Universal jokes tend to perform better, suggesting shared humor elements across cultures\")\n",
    "        elif correlation > 0.3:\n",
    "            st.write(\"• **Key Finding**: Culturally specific jokes may achieve higher peaks within target demographics\")\n",
    "        else:\n",
    "            st.write(\"• **Key Finding**: Mixed relationship suggests both universal and culture-specific humor strategies can be effective\")\n",
    "        \n",
    "        st.write(\"• **Strategic Recommendation**: Balance universal humor elements with targeted cultural content for optimal engagement\")\n",
    "        st.markdown('</div>', unsafe_allow_html=True)\n",
    "        \n",
    "        # Export functionality\n",
    "        st.subheader(\"Data Export\")\n",
    "        \n",
    "        if st.button(\"Generate Summary Report\"):\n",
    "            summary_stats = {\n",
    "                'Total Participants': processed_df['participant_id'].nunique(),\n",
    "                'Total Jokes': processed_df['joke_id'].nunique(),\n",
    "                'Overall Funny Rate': f\"{(processed_df['response'] == 'Yes').mean() * 100:.1f}%\",\n",
    "                'Comprehension Issues Rate': f\"{(processed_df['response'] == understand_key).mean() * 100:.1f}%\",\n",
    "                'Most Diverse Ethnicity': processed_df['ethnicity'].value_counts().index[0],\n",
    "                'Cultural Variance Range': f\"{cultural_df['cultural_variance'].min():.1f}-{cultural_df['cultural_variance'].max():.1f}\"\n",
    "            }\n",
    "            \n",
    "            st.json(summary_stats)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the dashboard code to a file\n",
    "with open('humor_dashboard.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(dashboard_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d8fe6",
   "metadata": {},
   "source": [
    "## Dashboard Setup Instructions\n",
    "\n",
    "The above cell creates a comprehensive Streamlit dashboard file that connects with your main analysis. Here's how to set it up:\n",
    "\n",
    "### Prerequisites\n",
    "```bash\n",
    "pip install streamlit plotly\n",
    "```\n",
    "\n",
    "### File Structure\n",
    "```\n",
    "Project/\n",
    "├── Dataset.csv                 # Your main dataset\n",
    "├── Project_File.ipynb         # Your main analysis notebook\n",
    "├── streamlit_dashboard.ipynb  # This notebook\n",
    "└── humor_dashboard.py         # Generated dashboard file\n",
    "```\n",
    "\n",
    "### Running the Dashboard\n",
    "```bash\n",
    "streamlit run humor_dashboard.py\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8872f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n",
      "These functions can be used in your main analysis or imported into other notebooks.\n"
     ]
    }
   ],
   "source": [
    "# HELPER FUNCTIONS FOR DATA PROCESSING\n",
    "# These functions can be imported into the main notebook if needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_age_groups(df, age_column):\n",
    "    \"\"\"Create age groups from age data\"\"\"\n",
    "    return pd.cut(df[age_column], \n",
    "                  bins=[0, 25, 35, 45, 100], \n",
    "                  labels=['18-25', '26-35', '36-45', '46+'])\n",
    "\n",
    "def calculate_joke_performance(df):\n",
    "    \"\"\"Calculate performance metrics for each joke\"\"\"\n",
    "    joke_stats = df.groupby('joke_id')['response'].value_counts().unstack(fill_value=0)\n",
    "    joke_stats['total'] = joke_stats.sum(axis=1)\n",
    "    joke_stats['funny_rate'] = (joke_stats['Yes'] / joke_stats['total'] * 100).round(1)\n",
    "    joke_stats['comprehension_issues'] = (joke_stats.get(\"I didn't understand\", 0) / joke_stats['total'] * 100).round(1)\n",
    "    return joke_stats\n",
    "\n",
    "def calculate_cultural_variance(df):\n",
    "    \"\"\"Calculate cultural variance for each joke\"\"\"\n",
    "    cultural_variance = []\n",
    "    \n",
    "    for joke_id in df['joke_id'].unique():\n",
    "        joke_data = df[df['joke_id'] == joke_id]\n",
    "        \n",
    "        # Performance by ethnicity\n",
    "        eth_performance = []\n",
    "        for ethnicity in joke_data['ethnicity'].unique():\n",
    "            eth_subset = joke_data[joke_data['ethnicity'] == ethnicity]\n",
    "            if len(eth_subset) >= 3:  # Minimum sample size\n",
    "                yes_rate = (eth_subset['response'] == 'Yes').mean() * 100\n",
    "                eth_performance.append(yes_rate)\n",
    "        \n",
    "        variance = np.std(eth_performance) if len(eth_performance) > 1 else 0\n",
    "        overall_performance = (joke_data['response'] == 'Yes').mean() * 100\n",
    "        \n",
    "        cultural_variance.append({\n",
    "            'joke_id': joke_id,\n",
    "            'cultural_variance': variance,\n",
    "            'overall_performance': overall_performance\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(cultural_variance)\n",
    "\n",
    "def export_summary_stats(df):\n",
    "    \"\"\"Export summary statistics\"\"\"\n",
    "    joke_stats = calculate_joke_performance(df)\n",
    "    \n",
    "    summary = {\n",
    "        'dataset_overview': {\n",
    "            'total_participants': df['participant_id'].nunique(),\n",
    "            'total_jokes': df['joke_id'].nunique(),\n",
    "            'total_responses': len(df),\n",
    "            'response_rate': len(df) / (df['participant_id'].nunique() * df['joke_id'].nunique())\n",
    "        },\n",
    "        'response_distribution': df['response'].value_counts().to_dict(),\n",
    "        'top_jokes': joke_stats.nlargest(5, 'funny_rate')['funny_rate'].to_dict(),\n",
    "        'comprehension_challenges': joke_stats.nlargest(5, 'comprehension_issues')['comprehension_issues'].to_dict(),\n",
    "        'demographic_diversity': {\n",
    "            'ethnicities': df['ethnicity'].nunique(),\n",
    "            'countries_residence': df['country_residence'].nunique(),\n",
    "            'countries_birth': df['country_birth'].nunique()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "print(\"Helper functions defined successfully!\")\n",
    "print(\"These functions can be used in your main analysis or imported into other notebooks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7c340",
   "metadata": {},
   "source": [
    "## Integration with Main Notebook\n",
    "\n",
    "### Option 1: Import Processed Data\n",
    "You can save the processed data from your main notebook and load it in the dashboard:\n",
    "\n",
    "```python\n",
    "# In your main notebook (Project_File.ipynb)\n",
    "final_df.to_csv('processed_humor_data.csv', index=False)\n",
    "\n",
    "# In the dashboard\n",
    "processed_df = pd.read_csv('processed_humor_data.csv')\n",
    "```\n",
    "\n",
    "### Option 2: Import Functions\n",
    "You can import the processing functions from your main notebook:\n",
    "\n",
    "```python\n",
    "# Create a separate utils.py file with your processing functions\n",
    "# Then import in the dashboard\n",
    "from utils import clean_joke_text, standardize_country, standardize_ethnicity\n",
    "```\n",
    "\n",
    "### Option 3: Direct Connection\n",
    "The dashboard currently replicates your data processing logic to maintain independence while ensuring consistency with your main analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Dashboard Features Summary\n",
    "\n",
    "### Dataset Overview\n",
    "- Key metrics and KPIs\n",
    "- Response distribution analysis\n",
    "- Data quality insights\n",
    "\n",
    "### Demographics\n",
    "- Age distribution visualization\n",
    "- Ethnicity and gender breakdowns\n",
    "- Geographic distribution analysis\n",
    "\n",
    "### Joke Performance\n",
    "- Individual joke performance rankings\n",
    "- Comprehension challenge identification\n",
    "- Interactive joke analysis with demographic breakdowns\n",
    "\n",
    "### Cultural Analysis\n",
    "- Cross-cultural humor patterns\n",
    "- Demographic comparison tools\n",
    "- Comprehension difficulty by culture\n",
    "\n",
    "### Advanced Insights\n",
    "- Joke performance correlation matrix\n",
    "- Cultural specificity analysis\n",
    "- Advanced analytics and export functionality\n",
    "\n",
    "The dashboard provides an interactive way to explore all the insights from your main analysis while allowing stakeholders to dive deeper into specific aspects of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
